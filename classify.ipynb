{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preemptive Research\n",
    "\n",
    "The Oxford Flowers102 dataset is a popular dataset on Kaggle and based off this leaderboard, https://paperswithcode.com/sota/image-classification-on-flowers-102, the best classification accuracy achieved is 99.76% by a CvT-W24 neural network trained with extra data. Without extra data, the best network was a TransBoost-ResNet50 model with 97.85% accuracy. This notebook attempts to recreate the TransBoost-Resnet50 model by using acquiring a pretrained ResNet50 model from Pytorch trained on ImageNet and performing transfer learning on it by training it on the Flowers102 dataset.    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training and saving the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pytorch and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.datasets import Flowers102\n",
    "from torchvision.transforms import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to GPU if its available\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'Found {torch.cuda.device_count()} GPU(s).')\n",
    "    device = torch.device('cuda:0')\n",
    "print(f'The device is set to {device}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize]),\n",
    "\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "\n",
    "    'test': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "training_set = datasets.ImageFolder('data2/train', transform=data_transforms['train'])\n",
    "validation_set = datasets.ImageFolder('data2/valid', transform=data_transforms['validation'])\n",
    "test_set = datasets.ImageFolder('data2/test', transform=data_transforms['test'])\n",
    "\n",
    "print(np.max(training_set.targets))\n",
    "idx_to_class = { v:k for k,v in training_set.class_to_idx.items()}\n",
    "\n",
    "# make sure training labels are the same as testing labels to ensure that testing works\n",
    "assert training_set.class_to_idx == test_set.class_to_idx\n",
    "\n",
    "# Pytorch's Image folder creates an internal representation of folder names to actual numbered labels \n",
    "# So we have to create another map to convert Pytorch label's to folder names and then convert those to actual flower names\n",
    "print(idx_to_class)\n",
    "\n",
    "\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "dataloaders = {'train': training_loader, 'val': validation_loader}\n",
    "dataset_sizes = {'train': len(training_set), 'val': len(validation_set)}\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))\n",
    "print('Test set has {} instances'.format(len(test_set)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check (Display images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    # PyTorch tensors assume the color channel is first\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.permute(1, 2, 0)\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image.numpy() + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# from https://github.com/bdevnani3/oxfordflowers102-label-name-mapping/blob/main/mapping.json\n",
    "with open('udacity_label_to_name.json', 'r') as f:\n",
    "    flower_to_name = json.load(f)\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(labels[0:8])\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "out = torchvision.utils.make_grid(images[0:8])\n",
    "imshow(out, title=[flower_to_name[idx_to_class[labels[j].item()]] for j in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying architecture for transfer learning\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(flower_to_name))\n",
    "model_ft = model.to(device)\n",
    "epochs = 9\n",
    "learning_rate = 0.001\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer_ft = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 3 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model using transfer learning\n",
    "model_tl = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Reloading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tl.cpu()\n",
    "torch.save({'arch': 'resNet50',\n",
    "            'state_dict': model_tl.state_dict(), \n",
    "            'class_to_idx': training_set.class_to_idx}, \n",
    "            'resNet50classifierHigherAcc.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path):\n",
    "    chpt = torch.load(checkpoint_path)\n",
    "    \n",
    "    if chpt['arch'] == 'resNet50':\n",
    "        model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Sorry base architecture note recognized\")\n",
    "        exit()\n",
    "    \n",
    "    model.class_to_idx = chpt['class_to_idx']\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Linear(num_ftrs, len(flower_to_name))\n",
    "\n",
    "    model.load_state_dict(chpt['state_dict'])\n",
    "    model.to(device) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tl = load_model('resNet50classifier.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_accuracy = 0 \n",
    "total = 0 \n",
    "with torch.no_grad(): \n",
    "\tfor data in test_loader: \n",
    "\t\tinputs, outputs = data\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\toutputs = outputs.to(device)\n",
    "\t\toutputs = outputs.to(torch.float32) \n",
    "\n",
    "\t\tpredicted_outputs = model_tl(inputs) \n",
    "\t\t_, predicted = torch.max(predicted_outputs, 1) \n",
    "\t\ttotal += outputs.size(0) \n",
    "\t\trunning_accuracy += (predicted == outputs).sum().item() \n",
    "\n",
    "print('Accuracy of the model based on the test set of 819 inputs is: %d %%' % (100 * running_accuracy / total))    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform transforms that were used in training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    adjust = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "    img_tensor = adjust(img)\n",
    "    return img_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Determining if the model finds the right label with high probability based on a hand-picked test set (smoke-testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    processed_image = process_image(image_path)\n",
    "    processed_image.unsqueeze_(0)\n",
    "    processed_image = processed_image.to(device)\n",
    "    probs = torch.exp(model.forward(processed_image))\n",
    "    top_probs, top_labs = probs.topk(topk)\n",
    "\n",
    "    top_probs = top_probs.cpu()\n",
    "    top_labs = top_labs.cpu()\n",
    "\n",
    "    idx_to_class = {}\n",
    "    for key, value in model.class_to_idx.items():\n",
    "        idx_to_class[value] = key\n",
    "\n",
    "    np_top_labs = top_labs[0].numpy()\n",
    "\n",
    "    top_labels = []\n",
    "    for label in np_top_labs:\n",
    "        top_labels.append(int(idx_to_class[label]))\n",
    "\n",
    "    top_flowers = [flower_to_name[idx_to_class[lab]] for lab in top_labels]\n",
    "    \n",
    "    return top_probs, top_labels, top_flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"./data2/test/1/image_06743.jpg\", model_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(image_path, model):\n",
    "    # Sets up our plot\n",
    "    plt.figure(figsize = (6,10))\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    # Set up title\n",
    "    flower_num = image_path.split('/')[2]\n",
    "    title_ = flower_to_name[flower_num] # Calls dictionary for name\n",
    "    # Plot flower\n",
    "    img = process_image(image_path)\n",
    "    plt.title(\"Actual Label:\", title_)\n",
    "    imshow(img, ax)\n",
    "    # Make prediction\n",
    "    top_probs, top_labels, top_flowers = predict(image_path, model) \n",
    "    top_probs = top_probs[0].detach().numpy() #converts from tensor to nparray\n",
    "    # Plot bar chart\n",
    "    plt.subplot(2,1,2)\n",
    "    sns.barplot(x=top_probs, y=top_flowers, color=sns.color_palette()[0])\n",
    "    plt.show()\n",
    "\n",
    "    print(top_probs, top_labels, top_flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_solution(\"data2/test/1/image_06743.jpg\", model_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    model.to(device)\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {flower_to_name[idx_to_class[preds[j].item()]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_tl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c86fd273e9253c57359a0bed40cc00cd462bd491eba5b63c05eacfeae5c445d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
